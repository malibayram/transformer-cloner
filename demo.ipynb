{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9e169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.9\n"
     ]
    }
   ],
   "source": [
    "import transformer_cloner as tc\n",
    "\n",
    "print(tc.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87bdf423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting distil-trainer\n",
      "  Downloading distil_trainer-0.1.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: accelerate>=0.24.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (1.8.1)\n",
      "Requirement already satisfied: datasets>=2.14.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (1.6.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.2.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (4.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (2.6.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (4.67.1)\n",
      "Requirement already satisfied: transformers>=4.35.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from distil-trainer) (5.0.0rc1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from accelerate>=0.24.0->distil-trainer) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from accelerate>=0.24.0->distil-trainer) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from accelerate>=0.24.0->distil-trainer) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from accelerate>=0.24.0->distil-trainer) (1.2.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from accelerate>=0.24.0->distil-trainer) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from datasets>=2.14.0->distil-trainer) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from datasets>=2.14.0->distil-trainer) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from datasets>=2.14.0->distil-trainer) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from datasets>=2.14.0->distil-trainer) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from datasets>=2.14.0->distil-trainer) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from datasets>=2.14.0->distil-trainer) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.1 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->distil-trainer) (0.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (0.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (4.14.1)\n",
      "Requirement already satisfied: anyio in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from pandas>=2.0.0->distil-trainer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from pandas>=2.0.0->distil-trainer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from pandas>=2.0.0->distil-trainer) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->distil-trainer) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.14.0->distil-trainer) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from requests>=2.32.2->datasets>=2.14.0->distil-trainer) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from scikit-learn>=1.0.0->distil-trainer) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from scikit-learn>=1.0.0->distil-trainer) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from scikit-learn>=1.0.0->distil-trainer) (3.6.0)\n",
      "Collecting transformers>=4.35.0 (from distil-trainer)\n",
      "  Using cached transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: Pillow in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from sentence-transformers>=2.2.0->distil-trainer) (10.4.0)\n",
      "Collecting huggingface_hub>=0.21.0 (from accelerate>=0.24.0->distil-trainer)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from transformers>=4.35.0->distil-trainer) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from transformers>=4.35.0->distil-trainer) (0.22.1)\n",
      "Requirement already satisfied: networkx in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from torch>=2.0.0->distil-trainer) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from torch>=2.0.0->distil-trainer) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from torch>=2.0.0->distil-trainer) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from torch>=2.0.0->distil-trainer) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from sympy==1.13.1->torch>=2.0.0->distil-trainer) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->distil-trainer) (2.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/alibayram/.pyenv/versions/3.13.3/lib/python3.13/site-packages (from typer-slim->huggingface_hub>=0.21.0->accelerate>=0.24.0->distil-trainer) (8.1.8)\n",
      "Downloading distil_trainer-0.1.3-py3-none-any.whl (48 kB)\n",
      "Using cached transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Installing collected packages: huggingface_hub, transformers, distil-trainer\n",
      "\u001b[2K  Attempting uninstall: huggingface_hub\n",
      "\u001b[2K    Found existing installation: huggingface_hub 1.2.3\n",
      "\u001b[2K    Uninstalling huggingface_hub-1.2.3:\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-1.2.3\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: transformers 5.0.0rc10/3\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling transformers-5.0.0rc1:m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-5.0.0rc1━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [transformers]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [distil-trainer]m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed distil-trainer-0.1.3 huggingface_hub-0.36.0 transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install distil-trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca24258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning SentenceTransformer from: google/embeddinggemma-300m\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "modules.json not found at google/embeddinggemma-300m/modules.json",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformer_cloner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerCloner\n\u001b[32m      3\u001b[39m cloner = SentenceTransformerCloner(\n\u001b[32m      4\u001b[39m     model_path=\u001b[33m\"\u001b[39m\u001b[33mgoogle/embeddinggemma-300m\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     target_tokenizer_id=\u001b[33m\"\u001b[39m\u001b[33malibayram/turkish-tokenizer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mcloner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m cloner.save(\u001b[33m\"\u001b[39m\u001b[33m./cloned_sentence_transformer\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pythons/transformer_cloner/src/transformer_cloner/sentence_transformer_cloner.py:176\u001b[39m, in \u001b[36mSentenceTransformerCloner.clone\u001b[39m\u001b[34m(self, verbose)\u001b[39m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCloning SentenceTransformer from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Load modules.json\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[38;5;28mself\u001b[39m.modules_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_modules_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.modules_info)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m modules:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/pythons/transformer_cloner/src/transformer_cloner/sentence_transformer_cloner.py:78\u001b[39m, in \u001b[36mSentenceTransformerCloner._load_modules_json\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m modules_path = os.path.join(\u001b[38;5;28mself\u001b[39m.model_path, \u001b[33m\"\u001b[39m\u001b[33mmodules.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(modules_path):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodules.json not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodules_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(modules_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.load(f)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: modules.json not found at google/embeddinggemma-300m/modules.json"
     ]
    }
   ],
   "source": [
    "from transformer_cloner import SentenceTransformerCloner\n",
    "\n",
    "cloner = SentenceTransformerCloner(\n",
    "    model_path=\"google/embeddinggemma-300m\",\n",
    "    target_tokenizer_id=\"alibayram/turkish-tokenizer\"\n",
    ")\n",
    "cloner.clone(verbose=True)\n",
    "cloner.save(\"./cloned_sentence_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a67aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are trying to use a model that was created with Sentence Transformers version 5.1.0, but you're currently using version 4.1.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8871684867148cabe818ef8e79e9ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"google/embeddinggemma-300m\")\n",
    "\n",
    "sentences = [\n",
    "    \"That is a happy person\",\n",
    "    \"That is a happy dog\",\n",
    "    \"That is a very happy person\",\n",
    "    \"Today is a sunny day\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)\n",
    "# [4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384c6d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.6366, 0.2575, 0.2891],\n",
      "        [0.6366, 1.0000, 0.2577, 0.3204],\n",
      "        [0.2575, 0.2577, 1.0000, 0.3144],\n",
      "        [0.2891, 0.3204, 0.3144, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Bu mutlu bir adamdır\",\n",
    "    \"Bu mutlu bir kadın\",\n",
    "    \"Akşam sinemaya gideceğim\",\n",
    "    \"Bugün hava güneşli\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1037f207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 2048, 'do_lower_case': False}) with Transformer model: Gemma3TextModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Dense({'in_features': 768, 'out_features': 3072, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
       "  (3): Dense({'in_features': 3072, 'out_features': 768, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
       "  (4): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a307f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a47c2dbd2184ebf9efc6536b27abeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783268c54609459bbd4d3c342f7321df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/830 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e985ec4cca5b4e67a9dbec6690f798fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1918b124eb84cdb9b0b16141a244122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb643739ff0d4ac2b118c55efef49bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/6.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5418679c97464696f46634e8918f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.57G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207de13bf8b64d159ce96a47de561cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70864763aa604008bd045364b2cb96b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForSeq2SeqLM\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"google/t5gemma-2-270m-270m\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/t5gemma-2-270m-270m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab7b76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33764286afd04d2f93c2f3675e140def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bd941d36654c89b3b8094746b1a3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df06f7cf43204126b1225c0ae2095163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d835c670f2df4eedabc27dd473e731ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a96ab8a1d84c14a53ef6adcd4aca05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd914507c82497f9376146c23db38b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorgu: Kolay bir kahvaltı tarifi nedir?\n",
      "   → Belge 1 Skoru: 67.36\n",
      "     İçerik: Güne enerjik başlamak için yulaf ezmesi, süt ve meyveyle hazırlanan basit bir ka...\n",
      "   → Belge 2 Skoru: 31.68\n",
      "     İçerik: Sabah saatleri, özellikle 07:00 ile 10:00 arası, açık havada yürüyüş yapmak için...\n",
      "   → Belge 3 Skoru: 7.06\n",
      "     İçerik: Türkiye'nin en uzun nehri Kızılırmak'tır. Sivas'tan doğar, Karadeniz'e dökülür v...\n",
      "\n",
      "Sorgu: Dış mekan yürüyüşü için en iyi saat hangisidir?\n",
      "   → Belge 1 Skoru: 28.14\n",
      "     İçerik: Güne enerjik başlamak için yulaf ezmesi, süt ve meyveyle hazırlanan basit bir ka...\n",
      "   → Belge 2 Skoru: 78.02\n",
      "     İçerik: Sabah saatleri, özellikle 07:00 ile 10:00 arası, açık havada yürüyüş yapmak için...\n",
      "   → Belge 3 Skoru: 18.70\n",
      "     İçerik: Türkiye'nin en uzun nehri Kızılırmak'tır. Sivas'tan doğar, Karadeniz'e dökülür v...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSorgu: Kolay bir kahvaltı tarifi nedir?\\n   → Belge 1 Skoru: 67.36\\n     İçerik: Güne enerjik başlamak için yulaf ezmesi, süt ve meyveyle hazırlanan basit bir ka...\\n   → Belge 2 Skoru: 31.68\\n     İçerik: Sabah saatleri, özellikle 07:00 ile 10:00 arası, açık havada yürüyüş yapmak için...\\n   → Belge 3 Skoru: 7.06\\n     İçerik: Türkiye'nin en uzun nehri Kızılırmak'tır. Sivas'tan doğar, Karadeniz'e dökülür v...\\n\\nSorgu: Dış mekan yürüyüşü için en iyi saat hangisidir?\\n   → Belge 1 Skoru: 28.14\\n     İçerik: Güne enerjik başlamak için yulaf ezmesi, süt ve meyveyle hazırlanan basit bir ka...\\n   → Belge 2 Skoru: 78.02\\n     İçerik: Sabah saatleri, özellikle 07:00 ile 10:00 arası, açık havada yürüyüş yapmak için...\\n   → Belge 3 Skoru: 18.70\\n     İçerik: Türkiye'nin en uzun nehri Kızılırmak'tır. Sivas'tan doğar, Karadeniz'e dökülür v...\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "# Görev: Web arama sorgusuna uygun bilgiyi içeren pasajları getir\n",
    "task = 'Given a Turkish search query, retrieve relevant passages written in Turkish that best answer the query'\n",
    "\n",
    "queries = [\n",
    "    get_detailed_instruct(task, 'Kolay bir kahvaltı tarifi nedir?'),\n",
    "    get_detailed_instruct(task, 'Dış mekan yürüyüşü için en iyi saat hangisidir?')\n",
    "]\n",
    "\n",
    "documents = [\n",
    "    \"Güne enerjik başlamak için yulaf ezmesi, süt ve meyveyle hazırlanan basit bir kahvaltı hem pratik hem de besleyicidir. Üzerine biraz bal ve tarçın eklerseniz lezzeti artar.\",\n",
    "    \"Sabah saatleri, özellikle 07:00 ile 10:00 arası, açık havada yürüyüş yapmak için idealdir. Bu saatlerde hava daha serin ve temiz olur, ayrıca gün ışığı vücut ritmini destekler.\",\n",
    "    \"Türkiye'nin en uzun nehri Kızılırmak'tır. Sivas'tan doğar, Karadeniz'e dökülür ve yaklaşık 1.355 kilometre uzunluğundadır.\"\n",
    "]\n",
    "\n",
    "input_texts = queries + documents\n",
    "\n",
    "model = SentenceTransformer('ytu-ce-cosmos/turkish-e5-large')\n",
    "\n",
    "embeddings = model.encode(input_texts, convert_to_tensor=True, normalize_embeddings=True)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "    print(f\"\\nSorgu: {query.split('Query: ')[-1]}\")\n",
    "    for j, doc in enumerate(documents):\n",
    "        print(f\"   → Belge {j+1} Skoru: {scores[i][j]:.2f}\")\n",
    "        print(f\"     İçerik: {doc[:80]}...\")\n",
    "\n",
    "\"\"\"\n",
    "Sorgu: Kolay bir kahvaltı tarifi nedir?\n",
    "   → Belge 1 Skoru: 67.36\n",
    "     İçerik: Güne enerjik başlamak için yulaf ezmesi, süt ve meyveyle hazırlanan basit bir ka...\n",
    "   → Belge 2 Skoru: 31.68\n",
    "     İçerik: Sabah saatleri, özellikle 07:00 ile 10:00 arası, açık havada yürüyüş yapmak için...\n",
    "   → Belge 3 Skoru: 7.06\n",
    "     İçerik: Türkiye'nin en uzun nehri Kızılırmak'tır. Sivas'tan doğar, Karadeniz'e dökülür v...\n",
    "\n",
    "Sorgu: Dış mekan yürüyüşü için en iyi saat hangisidir?\n",
    "   → Belge 1 Skoru: 28.14\n",
    "     İçerik: Güne enerjik başlamak için yulaf ezmesi, süt ve meyveyle hazırlanan basit bir ka...\n",
    "   → Belge 2 Skoru: 78.02\n",
    "     İçerik: Sabah saatleri, özellikle 07:00 ile 10:00 arası, açık havada yürüyüş yapmak için...\n",
    "   → Belge 3 Skoru: 18.70\n",
    "     İçerik: Türkiye'nin en uzun nehri Kızılırmak'tır. Sivas'tan doğar, Karadeniz'e dökülür v...\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87588084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are trying to use a model that was created with Sentence Transformers version 5.1.0, but you're currently using version 4.1.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02e7f2c939341e3baa6c0dbd4f03b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 2048, 'do_lower_case': False}) with Transformer model: Gemma3TextModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Dense({'in_features': 768, 'out_features': 3072, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
       "  (3): Dense({'in_features': 3072, 'out_features': 768, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
       "  (4): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "s_model = SentenceTransformer(\"./cloned_sentence_transformer\")\n",
    "s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fcb709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badb3932abe04719a1760f1c3e22e1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ddf487620a477788a17847a389cf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/alibayram/cloned_sentence_transformer/commit/94e8ab694b77c8aa564105957c6670a3f40e4d68'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model.push_to_hub(\"alibayram/cloned_sentence_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd5bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.8323, 0.5728, 0.6449],\n",
      "        [0.8323, 1.0000, 0.6608, 0.6795],\n",
      "        [0.5728, 0.6608, 1.0000, 0.7234],\n",
      "        [0.6449, 0.6795, 0.7234, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"Bu mutlu bir adamdır\",\n",
    "    \"Bu mutlu bir kadın\",\n",
    "    \"Akşam sinemaya gideceğim\",\n",
    "    \"Bugün hava güneşli\"\n",
    "]\n",
    "embeddings = s_model.encode(sentences)\n",
    "\n",
    "similarities = s_model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32dfb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cf1fa033a9402fa47a04de0262bdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/314 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Gemma3ForCausalLM(\n",
       "  (model): Gemma3TextModel(\n",
       "    (embed_tokens): Gemma3TextScaledWordEmbedding(65538, 768, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Gemma3DecoderLayer(\n",
       "        (self_attn): Gemma3Attention(\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "          (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Gemma3MLP(\n",
       "          (gate_proj): Linear(in_features=768, out_features=1152, bias=False)\n",
       "          (up_proj): Linear(in_features=768, out_features=1152, bias=False)\n",
       "          (down_proj): Linear(in_features=1152, out_features=768, bias=False)\n",
       "          (act_fn): GELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma3RMSNorm((768,), eps=1e-06)\n",
       "    (rotary_emb): Gemma3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=65538, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Gemma3ForCausalLM\n",
    "\n",
    "g_model = Gemma3ForCausalLM.from_pretrained(\"cloned_sentence_transformer\")\n",
    "\n",
    "g_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee782a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28249dc1e29a4d3bb5d35c38f9fc8c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2196e28b8d4f008cd332bfbc1d797e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/alibayram/cloned_sentence_transformer_just_model/commit/6e97c1750995af25afb7c4065692f73e8bbd6507', commit_message='Upload Gemma3ForCausalLM', commit_description='', oid='6e97c1750995af25afb7c4065692f73e8bbd6507', pr_url=None, repo_url=RepoUrl('https://huggingface.co/alibayram/cloned_sentence_transformer_just_model', endpoint='https://huggingface.co', repo_type='model', repo_id='alibayram/cloned_sentence_transformer_just_model'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_model.push_to_hub(\"alibayram/cloned_sentence_transformer_just_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
